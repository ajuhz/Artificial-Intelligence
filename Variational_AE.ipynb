{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Variational AE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMw6mn8OQyTl4W+cBT6z0w6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajuhz/Artificial-Intelligence/blob/master/Variational_AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atSU0nKNDi7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image # to save the reconstrcted image in tensor"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk8TRSx1EZqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define hyperparameter\n",
        "image_size=784 #MNIST dataset image size 28x28 \n",
        "hidden_dim = 400\n",
        "latent_dim = 20\n",
        "batch_size = 128\n",
        "epochs = 10\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J2RyfPnE9Uf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#setting device GPU/CPU \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhuLZMUWE3TH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading dataset and creating dataloader\n",
        "train_dataset=torchvision.datasets.MNIST('../../Data',\n",
        "                                         train=True,\n",
        "                                         transform=transforms.ToTensor(),\n",
        "                                         download=True)\n",
        "test_dataset=torchvision.datasets.MNIST('../../Data',\n",
        "                                         train=False,\n",
        "                                         transform=transforms.ToTensor())\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                                 batch_size=batch_size,\n",
        "                                                 shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                                 batch_size=batch_size,\n",
        "                                                 shuffle=True)\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwTzy3ZcGrlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a directory for the result image\n",
        "result_dir='results'\n",
        "if not os.path.exists(result_dir):\n",
        "  os.makedirs(result_dir)\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JVOWk5pJVxf",
        "colab_type": "text"
      },
      "source": [
        "**Variational Autoencoder**\n",
        "![vae](https://user-images.githubusercontent.com/30661597/78418103-a2047200-766b-11ea-8205-c7e5712715f4.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d62JgCIwJYU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining th model\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VAE,self).__init__()\n",
        "    self.fc1=nn.Linear(image_size,hidden_dim)\n",
        "    self.fc2_mean=nn.Linear(hidden_dim,latent_dim)\n",
        "    self.fc2_std=nn.Linear(hidden_dim,latent_dim)\n",
        "    self.fc3=nn.Linear(latent_dim,hidden_dim)\n",
        "    self.fc4=nn.Linear(hidden_dim,image_size)\n",
        "  \n",
        "  def encode(self,x):\n",
        "    h=F.relu(self.fc1(x))\n",
        "    mu = self.fc2_mean(h)\n",
        "    logvar = self.fc2_std(h)\n",
        "    return mu,logvar\n",
        "  \n",
        "  def reparameterize(self, mu, logvar):\n",
        "    std = torch.exp(logvar/2)\n",
        "    eps = torch.randn_like(std)\n",
        "    return (mu + eps * std)\n",
        "  \n",
        "  def decode(self,z):\n",
        "    h= F.relu(self.fc3(z))\n",
        "    out = torch.sigmoid(self.fc4(h))\n",
        "    return out\n",
        "\n",
        "  def forward(self,x):\n",
        "    mu,logvar=self.encode(x.view(-1, image_size))\n",
        "    z=self.reparameterize(mu,logvar)\n",
        "    reconstructed=self.decode(z)\n",
        "    return reconstructed, mu, logvar\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzFCWioTOtoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model and optimizer obejct\n",
        "model = VAE().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuYbHlZqPmUL",
        "colab_type": "text"
      },
      "source": [
        "$Loss = -E[\\log P(X | z)]+D_{K L}[N(\\mu(X), \\Sigma(X)) \\| N(0,1)]$\n",
        "#### $D_{K L}[N(\\mu(X), \\Sigma(X)) \\| N(0,1)]=\\frac{1}{2} \\sum_{k}\\left(\\exp (\\Sigma(X))+\\mu^{2}(X)-1-\\Sigma(X)\\right)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnTypjwEPtpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define loss function\n",
        "def loss_fn(reconstructed,original,mu,logvar):\n",
        "  rc_loss = F.binary_cross_entropy(reconstructed,original.view(-1,image_size),reduction='sum')\n",
        "  kld= 0.5*(torch.sum(logvar.exp()+mu.pow(2)-1-logvar))\n",
        "  return rc_loss + kld"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDEpo-GBTCh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to Train the model \n",
        "def train(epochs):\n",
        "  model.train()\n",
        "  train_loss=0\n",
        "  for i,(images,_) in enumerate(train_loader):\n",
        "    images=images.to(device)\n",
        "    reconstructed, mu, logvar = model(images)\n",
        "    loss=loss_fn(reconstructed,images,mu,logvar)\n",
        "    train_loss += loss.item()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i%100==0:\n",
        "      print(\"Train Epoch {} [Batch {}/{}]\\tLoss: {:.3f}\".format(epoch, i, len(train_loader), loss.item()/len(images)))\n",
        "  print('=====> Epoch {}, Average Loss: {:.3f}'.format(epoch, train_loss/len(train_loader.dataset)))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rPNZme2TJ-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test the model\n",
        "# Test function\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, _) in enumerate(test_loader):\n",
        "            images = images.to(device)\n",
        "            reconstructed, mu, logvar = model(images)\n",
        "            test_loss += loss_fn(reconstructed, images, mu, logvar).item()\n",
        "            if batch_idx == 0:\n",
        "                comparison = torch.cat([images[:5], reconstructed.view(batch_size, 1, 28, 28)[:5]])\n",
        "                save_image(comparison.cpu(), 'results/reconstruction_' + str(epoch) + '.png', nrow = 5)\n",
        "\n",
        "    print('=====> Average Test Loss: {:.3f}'.format(test_loss/len(test_loader.dataset)))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd-dkTt7TLs4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c633b87c-047a-48cf-89e7-b7653f96f836"
      },
      "source": [
        "# Main function\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    with torch.no_grad():\n",
        "        # Get rid of the encoder and sample z from the gaussian ditribution and feed it to the decoder to generate samples\n",
        "        sample = torch.randn(64,20).to(device)\n",
        "        generated = model.decode(sample).cpu()\n",
        "        save_image(generated.view(64,1,28,28), 'results/sample_' + str(epoch) + '.png')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch 1 [Batch 0/469]\tLoss: 125.698\n",
            "Train Epoch 1 [Batch 100/469]\tLoss: 124.848\n",
            "Train Epoch 1 [Batch 200/469]\tLoss: 123.126\n",
            "Train Epoch 1 [Batch 300/469]\tLoss: 120.954\n",
            "Train Epoch 1 [Batch 400/469]\tLoss: 115.409\n",
            "=====> Epoch 1, Average Loss: 121.633\n",
            "=====> Average Test Loss: 115.901\n",
            "Train Epoch 2 [Batch 0/469]\tLoss: 114.493\n",
            "Train Epoch 2 [Batch 100/469]\tLoss: 115.269\n",
            "Train Epoch 2 [Batch 200/469]\tLoss: 113.379\n",
            "Train Epoch 2 [Batch 300/469]\tLoss: 117.440\n",
            "Train Epoch 2 [Batch 400/469]\tLoss: 113.625\n",
            "=====> Epoch 2, Average Loss: 114.721\n",
            "=====> Average Test Loss: 112.308\n",
            "Train Epoch 3 [Batch 0/469]\tLoss: 110.809\n",
            "Train Epoch 3 [Batch 100/469]\tLoss: 112.703\n",
            "Train Epoch 3 [Batch 200/469]\tLoss: 112.672\n",
            "Train Epoch 3 [Batch 300/469]\tLoss: 112.762\n",
            "Train Epoch 3 [Batch 400/469]\tLoss: 111.055\n",
            "=====> Epoch 3, Average Loss: 111.736\n",
            "=====> Average Test Loss: 109.838\n",
            "Train Epoch 4 [Batch 0/469]\tLoss: 112.761\n",
            "Train Epoch 4 [Batch 100/469]\tLoss: 111.337\n",
            "Train Epoch 4 [Batch 200/469]\tLoss: 114.400\n",
            "Train Epoch 4 [Batch 300/469]\tLoss: 112.808\n",
            "Train Epoch 4 [Batch 400/469]\tLoss: 108.376\n",
            "=====> Epoch 4, Average Loss: 110.009\n",
            "=====> Average Test Loss: 108.568\n",
            "Train Epoch 5 [Batch 0/469]\tLoss: 107.665\n",
            "Train Epoch 5 [Batch 100/469]\tLoss: 103.524\n",
            "Train Epoch 5 [Batch 200/469]\tLoss: 109.436\n",
            "Train Epoch 5 [Batch 300/469]\tLoss: 110.538\n",
            "Train Epoch 5 [Batch 400/469]\tLoss: 112.182\n",
            "=====> Epoch 5, Average Loss: 108.802\n",
            "=====> Average Test Loss: 107.872\n",
            "Train Epoch 6 [Batch 0/469]\tLoss: 110.247\n",
            "Train Epoch 6 [Batch 100/469]\tLoss: 105.968\n",
            "Train Epoch 6 [Batch 200/469]\tLoss: 103.219\n",
            "Train Epoch 6 [Batch 300/469]\tLoss: 113.286\n",
            "Train Epoch 6 [Batch 400/469]\tLoss: 103.747\n",
            "=====> Epoch 6, Average Loss: 107.942\n",
            "=====> Average Test Loss: 106.928\n",
            "Train Epoch 7 [Batch 0/469]\tLoss: 106.829\n",
            "Train Epoch 7 [Batch 100/469]\tLoss: 104.861\n",
            "Train Epoch 7 [Batch 200/469]\tLoss: 105.327\n",
            "Train Epoch 7 [Batch 300/469]\tLoss: 106.650\n",
            "Train Epoch 7 [Batch 400/469]\tLoss: 105.369\n",
            "=====> Epoch 7, Average Loss: 107.248\n",
            "=====> Average Test Loss: 106.553\n",
            "Train Epoch 8 [Batch 0/469]\tLoss: 108.676\n",
            "Train Epoch 8 [Batch 100/469]\tLoss: 104.208\n",
            "Train Epoch 8 [Batch 200/469]\tLoss: 109.088\n",
            "Train Epoch 8 [Batch 300/469]\tLoss: 106.697\n",
            "Train Epoch 8 [Batch 400/469]\tLoss: 109.906\n",
            "=====> Epoch 8, Average Loss: 106.777\n",
            "=====> Average Test Loss: 106.071\n",
            "Train Epoch 9 [Batch 0/469]\tLoss: 106.533\n",
            "Train Epoch 9 [Batch 100/469]\tLoss: 105.951\n",
            "Train Epoch 9 [Batch 200/469]\tLoss: 108.811\n",
            "Train Epoch 9 [Batch 300/469]\tLoss: 107.226\n",
            "Train Epoch 9 [Batch 400/469]\tLoss: 107.209\n",
            "=====> Epoch 9, Average Loss: 106.359\n",
            "=====> Average Test Loss: 105.729\n",
            "Train Epoch 10 [Batch 0/469]\tLoss: 108.028\n",
            "Train Epoch 10 [Batch 100/469]\tLoss: 106.336\n",
            "Train Epoch 10 [Batch 200/469]\tLoss: 101.147\n",
            "Train Epoch 10 [Batch 300/469]\tLoss: 104.644\n",
            "Train Epoch 10 [Batch 400/469]\tLoss: 106.931\n",
            "=====> Epoch 10, Average Loss: 105.939\n",
            "=====> Average Test Loss: 105.373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOmO9sweVYyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}